# Embodied AI Agent Configuration

# Hardware platform settings
hardware:
  # Current platform to use
  platform: mac  # 'mac' or 'robot'

  # Sensor configurations
  sensors:
    # Default sensors for all platforms
    default: []

    # Mac-specific sensors
    mac:
      - name: webcam
        type: camera
        enabled: true
        frame_interval: 5.0  # seconds between frames
        simulate: true
        simulate_data:
          - "A desk with a MacBook Pro, an external monitor, and a coffee mug. The code editor is open on the screen."
          - "A home office with a desk, computer, bookshelf, and window. Natural light coming through the window."
          - "A person sitting at a desk, typing on a keyboard while looking at a computer screen."
          - "An empty desk with just a computer, the screen shows a terminal window with logs scrolling by."

      - name: microphone
        type: microphone
        enabled: true
        capture_interval: 3.0  # seconds between audio captures
        simulate: true
        simulate_data:
          - "Hello, agent. Can you hear me?"
          - "What's the current status of the system?"
          - "Run a diagnostic check please."
          - "Tell me what you're currently thinking about."
          - "What's your current emotional state?"

    # Robot-specific sensors
    robot:
      - name: camera
        type: camera
        enabled: true
        frame_interval: 1.0  # seconds between frames
        simulate: true

      - name: microphone
        type: microphone
        enabled: true
        capture_interval: 2.0  # seconds between audio captures
        simulate: true

      - name: lidar
        type: lidar
        enabled: true
        read_interval: 1.0  # seconds between readings
        simulate: true

      - name: temperature
        type: temperature
        enabled: true
        read_interval: 10.0  # seconds between readings
        simulate: true
        simulate_min: 15.0
        simulate_max: 30.0
        simulate_unit: "Â°C"

      - name: battery
        type: battery
        enabled: true
        read_interval: 30.0  # seconds between readings
        simulate: true
        simulate_min: 0.0
        simulate_max: 100.0
        simulate_unit: "%"

  # Actuator configurations
  actuators:
    # Default actuators for all platforms
    default: []

    # Mac-specific actuators
    mac:
      - name: screen
        type: display
        enabled: true
        output_file: "memory/output/display.txt"
        simulate: true

      - name: speakers
        type: speaker
        enabled: true
        output_file: "memory/output/speech.txt"
        simulate: true

    # Robot-specific actuators
    robot:
      - name: screen
        type: display
        enabled: true
        simulate: true

      - name: speaker
        type: speaker
        enabled: true
        simulate: true

      - name: left_wheel
        type: motor
        motor_type: wheel
        enabled: true
        simulate: true

      - name: right_wheel
        type: motor
        motor_type: wheel
        enabled: true
        simulate: true

# LLM settings
llm:
  # Number of worker threads for LLM processing
  num_workers: 4

  # Model configurations
  models:
    # Perception models
    vision_interpreter:
      type: ollama
      model_id: llama3.2-vision:latest
      api_base: http://localhost:11434/api

    audio_interpreter:
      type: ollama
      model_id: llama3:latest
      api_base: http://localhost:11434/api

    general_interpreter:
      type: ollama
      model_id: llama3:latest
      api_base: http://localhost:11434/api

    # Cognition models
    reasoning_engine:
      type: ollama
      model_id: llama3:latest
      api_base: http://localhost:11434/api

    emotion_engine:
      type: ollama
      model_id: llama3:latest
      api_base: http://localhost:11434/api

    planning_engine:
      type: ollama
      model_id: llama3:latest
      api_base: http://localhost:11434/api

    # Consciousness model
    consciousness_engine:
      type: ollama
      model_id: llama3:latest
      api_base: http://localhost:11434/api

# Memory settings
memory:
  # Directory for memory storage
  memory_dir: "memory"

  # Capacity limits
  perception_capacity: 100  # Number of recent perceptions to keep in memory
  working_memory_capacity: 20  # Number of items in working memory

# Perception module settings
perception:
  # LLM models to use for perception
  vision_model: vision_interpreter
  audio_model: audio_interpreter
  general_model: general_interpreter

  # Processing intervals for different sensor types (seconds)
  process_intervals:
    camera: 5.0
    microphone: 3.0
    lidar: 2.0
    temperature: 10.0
    battery: 30.0
    general: 5.0

# Cognition module settings
cognition:
  # LLM models to use for cognition
  reasoning_model: reasoning_engine
  emotion_model: emotion_engine
  planning_model: planning_engine

  # Processing intervals (seconds)
  reasoning_interval: 5.0
  emotion_interval: 3.0
  planning_interval: 10.0

# Consciousness module settings
consciousness:
  # LLM model to use for consciousness
  model: consciousness_engine

  # Processing interval (seconds)
  process_interval: 0.5

  # Maximum length of internal monologue
  max_monologue_length: 50

  # Conversation initiation settings
  enable_conversation_initiation: true
  min_initiation_interval: 1800.0  # 30 minutes minimum between initiated conversations
  idle_initiation_threshold: 900.0  # 15 minutes of idle time before possibly initiating

# Autonomy module settings
autonomy:
  # LLM model to use for autonomous thinking
  model: reasoning_engine

  # Thought generation settings
  thought_interval: 20.0  # seconds between autonomous thoughts
  idle_threshold: 120.0  # seconds of inactivity before increasing thought frequency

  # Metacognition settings
  metacognition_interval: 600.0  # 10 minutes between metacognitive reflections

  # Interest and curiosity settings
  min_interest_threshold: 0.4  # Minimum interest score to consider a topic

# Processing settings
processing:
  # Processing intervals for different modules (seconds)
  perception_interval: 0.2
  cognition_interval: 0.5
  consciousness_interval: 0.3
